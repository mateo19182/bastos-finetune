nohup: ignoring input
Unsloth unsuccessfully patched LoraLayer.update_layer. Please file a bug report.
Luckily, your training run will still work in the meantime!
wandb: Currently logged in as: m19182 (finentune). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /home/mateo/bastos-finetune/wandb/run-20240726_102437-ge8tkz0r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-aardvark-1
wandb: â­ï¸ View project at https://wandb.ai/finentune/bastos
wandb: ğŸš€ View run at https://wandb.ai/finentune/bastos/runs/ge8tkz0r
Not an error, but Unsloth cannot patch MLP layers with our manual autograd engine since either LoRA adapters
are not enabled or a bias term (like in Qwen) is used.
Not an error, but Unsloth cannot patch Attention layers with our manual autograd engine since either LoRA adapters
are not enabled or a bias term (like in Qwen) is used.
Not an error, but Unsloth cannot patch O projection layer with our manual autograd engine since either LoRA adapters
are not enabled or a bias term (like in Qwen) is used.
Unsloth 2024.7 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.
ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
Dataset size: 200
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.69 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Map (num_proc=2):   0%|          | 0/200 [00:00<?, ? examples/s]Map (num_proc=2):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [00:00<00:00, 256.79 examples/s]Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 374.57 examples/s]
max_steps is given, it will override any value given in num_train_epochs
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1
   \\   /|    Num examples = 200 | Num Epochs = 4
O^O/ \_/ \    Batch size per device = 2 | Gradient Accumulation steps = 4
\        /    Total batch size = 8 | Total steps = 80
 "-____-"     Number of trainable parameters = 41,943,040
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
Starting training...
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:07<10:27,  7.95s/it]                                                1%|â–         | 1/80 [00:07<10:27,  7.95s/it]  2%|â–         | 2/80 [00:13<08:15,  6.35s/it]                                                2%|â–         | 2/80 [00:13<08:15,  6.35s/it]  4%|â–         | 3/80 [00:40<20:15, 15.78s/it]                                                4%|â–         | 3/80 [00:40<20:15, 15.78s/it]  5%|â–Œ         | 4/80 [00:44<14:30, 11.45s/it]                                                5%|â–Œ         | 4/80 [00:44<14:30, 11.45s/it]  6%|â–‹         | 5/80 [01:11<21:15, 17.01s/it]                                                6%|â–‹         | 5/80 [01:11<21:15, 17.01s/it]  8%|â–Š         | 6/80 [01:17<16:13, 13.15s/it]                                                8%|â–Š         | 6/80 [01:17<16:13, 13.15s/it]  9%|â–‰         | 7/80 [01:22<12:37, 10.38s/it]                                                9%|â–‰         | 7/80 [01:22<12:37, 10.38s/it] 10%|â–ˆ         | 8/80 [01:46<17:55, 14.94s/it]                                               10%|â–ˆ         | 8/80 [01:46<17:55, 14.94s/it] 11%|â–ˆâ–        | 9/80 [01:50<13:38, 11.52s/it]                                               11%|â–ˆâ–        | 9/80 [01:50<13:38, 11.52s/it] 12%|â–ˆâ–        | 10/80 [02:14<17:56, 15.38s/it]                                                12%|â–ˆâ–        | 10/80 [02:14<17:56, 15.38s/it] 14%|â–ˆâ–        | 11/80 [02:19<13:45, 11.96s/it]                                                14%|â–ˆâ–        | 11/80 [02:19<13:45, 11.96s/it] 15%|â–ˆâ–Œ        | 12/80 [02:26<12:02, 10.63s/it]                                                15%|â–ˆâ–Œ        | 12/80 [02:26<12:02, 10.63s/it] 16%|â–ˆâ–‹        | 13/80 [02:52<17:09, 15.36s/it]                                                16%|â–ˆâ–‹        | 13/80 [02:52<17:09, 15.36s/it] 18%|â–ˆâ–Š        | 14/80 [03:00<14:27, 13.14s/it]                                                18%|â–ˆâ–Š        | 14/80 [03:00<14:27, 13.14s/it] 19%|â–ˆâ–‰        | 15/80 [03:25<17:51, 16.48s/it]                                                19%|â–ˆâ–‰        | 15/80 [03:25<17:51, 16.48s/it] 20%|â–ˆâ–ˆ        | 16/80 [03:30<13:58, 13.11s/it]                                                20%|â–ˆâ–ˆ        | 16/80 [03:30<13:58, 13.11s/it] 21%|â–ˆâ–ˆâ–       | 17/80 [03:35<11:18, 10.77s/it]                                                21%|â–ˆâ–ˆâ–       | 17/80 [03:35<11:18, 10.77s/it] 22%|â–ˆâ–ˆâ–       | 18/80 [04:00<15:22, 14.88s/it]                                                22%|â–ˆâ–ˆâ–       | 18/80 [04:00<15:22, 14.88s/it] 24%|â–ˆâ–ˆâ–       | 19/80 [04:03<11:43, 11.53s/it]                                                24%|â–ˆâ–ˆâ–       | 19/80 [04:03<11:43, 11.53s/it] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [04:27<15:01, 15.03s/it]                                                25%|â–ˆâ–ˆâ–Œ       | 20/80 [04:27<15:01, 15.03s/it] 26%|â–ˆâ–ˆâ–‹       | 21/80 [04:31<11:35, 11.79s/it]                                                26%|â–ˆâ–ˆâ–‹       | 21/80 [04:31<11:35, 11.79s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [04:35<09:09,  9.48s/it]                                                28%|â–ˆâ–ˆâ–Š       | 22/80 [04:35<09:09,  9.48s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [05:04<14:28, 15.23s/it]                                                29%|â–ˆâ–ˆâ–‰       | 23/80 [05:04<14:28, 15.23s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [05:09<11:26, 12.25s/it]                                                30%|â–ˆâ–ˆâ–ˆ       | 24/80 [05:09<11:26, 12.25s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [05:33<14:26, 15.76s/it]                                                31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [05:33<14:26, 15.76s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 26/80 [05:39<11:41, 12.98s/it]                                                32%|â–ˆâ–ˆâ–ˆâ–      | 26/80 [05:39<11:41, 12.98s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [05:44<09:09, 10.37s/it]                                                34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [05:44<09:09, 10.37s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [06:08<12:36, 14.55s/it]                                                35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [06:08<12:36, 14.55s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [06:12<09:46, 11.51s/it]                                                36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [06:12<09:46, 11.51s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [06:41<13:51, 16.62s/it]                                                38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [06:41<13:51, 16.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [06:44<10:21, 12.69s/it]                                                39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [06:44<10:21, 12.69s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [06:52<08:53, 11.11s/it]                                                40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [06:52<08:53, 11.11s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [07:18<12:20, 15.75s/it]                                                41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [07:18<12:20, 15.75s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/80 [07:25<09:53, 12.90s/it]                                                42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/80 [07:25<09:53, 12.90s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [07:50<12:23, 16.52s/it]                                                44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [07:50<12:23, 16.52s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [07:55<09:38, 13.16s/it]                                                45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [07:55<09:38, 13.16s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [08:00<07:44, 10.80s/it]                                                46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [08:00<07:44, 10.80s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [08:24<10:20, 14.78s/it]                                                48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [08:24<10:20, 14.78s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [08:32<08:34, 12.54s/it]                                                49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [08:32<08:34, 12.54s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [08:59<11:14, 16.86s/it]                                                50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [08:59<11:14, 16.86s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [09:03<08:32, 13.13s/it]                                                51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [09:03<08:32, 13.13s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42/80 [09:08<06:46, 10.69s/it]                                                52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42/80 [09:08<06:46, 10.69s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [09:32<09:05, 14.75s/it]                                                54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [09:32<09:05, 14.75s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [09:40<07:36, 12.69s/it]                                                55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [09:40<07:36, 12.69s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [10:04<09:19, 15.99s/it]                                                56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [10:04<09:19, 15.99s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [10:08<07:07, 12.57s/it]                                                57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [10:08<07:07, 12.57s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [10:14<05:43, 10.40s/it]                                                59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [10:14<05:43, 10.40s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [10:39<08:00, 15.01s/it]                                                60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [10:39<08:00, 15.01s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [10:44<06:04, 11.75s/it]                                                61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [10:44<06:04, 11.75s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/80 [11:08<07:45, 15.51s/it]                                                62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/80 [11:08<07:45, 15.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [11:13<06:02, 12.49s/it]                                                64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [11:13<06:02, 12.49s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [11:19<04:48, 10.32s/it]                                                65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [11:19<04:48, 10.32s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [11:43<06:29, 14.43s/it]                                                66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [11:43<06:29, 14.43s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [11:49<05:13, 12.04s/it]                                                68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [11:49<05:13, 12.04s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [12:14<06:41, 16.04s/it]                                                69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [12:14<06:41, 16.04s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [12:18<04:57, 12.39s/it]                                                70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [12:18<04:57, 12.39s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [12:24<03:59, 10.40s/it]                                                71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [12:24<03:59, 10.40s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 58/80 [12:51<05:34, 15.22s/it]                                                72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 58/80 [12:51<05:34, 15.22s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [12:58<04:27, 12.75s/it]                                                74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [12:58<04:27, 12.75s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [13:24<05:35, 16.77s/it]                                                75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [13:24<05:35, 16.77s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [13:28<04:08, 13.06s/it]                                                76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [13:28<04:08, 13.06s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [13:33<03:10, 10.60s/it]                                                78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [13:33<03:10, 10.60s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [13:58<04:15, 15.01s/it]                                                79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [13:58<04:15, 15.01s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [14:05<03:21, 12.57s/it]                                                80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [14:05<03:21, 12.57s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [14:32<04:13, 16.90s/it]                                                81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [14:32<04:13, 16.90s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 66/80 [14:36<03:01, 12.97s/it]                                                82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 66/80 [14:36<03:01, 12.97s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [14:41<02:18, 10.65s/it]                                                84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [14:41<02:18, 10.65s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [15:10<03:11, 16.00s/it]                                                85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [15:10<03:11, 16.00s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [15:15<02:19, 12.65s/it]                                                86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [15:15<02:19, 12.65s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [15:39<02:42, 16.29s/it]                                                88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [15:39<02:42, 16.29s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [15:44<01:55, 12.83s/it]                                                89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [15:44<01:55, 12.83s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [15:49<01:22, 10.36s/it]                                                90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [15:49<01:22, 10.36s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [16:13<01:42, 14.62s/it]                                                91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [16:13<01:42, 14.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 74/80 [16:18<01:10, 11.81s/it]                                                92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 74/80 [16:18<01:10, 11.81s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [16:45<01:20, 16.20s/it]                                                94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [16:45<01:20, 16.20s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [16:50<00:51, 12.82s/it]                                                95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [16:50<00:51, 12.82s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [16:56<00:32, 10.68s/it]                                                96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [16:56<00:32, 10.68s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [17:20<00:29, 14.84s/it]                                                98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [17:20<00:29, 14.84s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [17:24<00:11, 11.59s/it]                                                99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [17:24<00:11, 11.59s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [17:49<00:00, 15.58s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [17:49<00:00, 15.58s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [17:51<00:00, 15.58s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [17:51<00:00, 13.39s/it]
{'loss': 2.8671, 'grad_norm': 0.45255616307258606, 'learning_rate': 0.0001, 'epoch': 0.04}
{'loss': 2.7843, 'grad_norm': 0.5766644477844238, 'learning_rate': 0.0002, 'epoch': 0.08}
{'loss': 2.8813, 'grad_norm': 0.6646426320075989, 'learning_rate': 0.0003, 'epoch': 0.12}
{'loss': 2.7391, 'grad_norm': 0.6037139892578125, 'learning_rate': 0.0004, 'epoch': 0.16}
{'loss': 2.5031, 'grad_norm': 0.526724100112915, 'learning_rate': 0.0005, 'epoch': 0.2}
{'loss': 2.6722, 'grad_norm': 0.47797271609306335, 'learning_rate': 0.0004933333333333334, 'epoch': 0.24}
{'loss': 2.2733, 'grad_norm': 0.5986953973770142, 'learning_rate': 0.0004866666666666667, 'epoch': 0.28}
{'loss': 2.321, 'grad_norm': 0.42159485816955566, 'learning_rate': 0.00048, 'epoch': 0.32}
{'loss': 2.3311, 'grad_norm': 0.43944916129112244, 'learning_rate': 0.00047333333333333336, 'epoch': 0.36}
{'loss': 2.0285, 'grad_norm': 0.4654865562915802, 'learning_rate': 0.00046666666666666666, 'epoch': 0.4}
{'loss': 2.0646, 'grad_norm': 0.39786839485168457, 'learning_rate': 0.00046, 'epoch': 0.44}
{'loss': 2.11, 'grad_norm': 0.3247736394405365, 'learning_rate': 0.0004533333333333333, 'epoch': 0.48}
{'loss': 2.4682, 'grad_norm': 0.45549461245536804, 'learning_rate': 0.00044666666666666666, 'epoch': 0.52}
{'loss': 2.3632, 'grad_norm': 0.3898145258426666, 'learning_rate': 0.00044, 'epoch': 0.56}
{'loss': 2.0004, 'grad_norm': 0.46137863397598267, 'learning_rate': 0.00043333333333333337, 'epoch': 0.6}
{'loss': 2.0986, 'grad_norm': 0.39024701714515686, 'learning_rate': 0.0004266666666666667, 'epoch': 0.64}
{'loss': 2.0759, 'grad_norm': 0.4270508885383606, 'learning_rate': 0.00042, 'epoch': 0.68}
{'loss': 2.1876, 'grad_norm': 0.4054321050643921, 'learning_rate': 0.0004133333333333333, 'epoch': 0.72}
{'loss': 2.1672, 'grad_norm': 0.45364221930503845, 'learning_rate': 0.00040666666666666667, 'epoch': 0.76}
{'loss': 1.8181, 'grad_norm': 0.44175463914871216, 'learning_rate': 0.0004, 'epoch': 0.8}
{'loss': 2.2162, 'grad_norm': 0.5176711082458496, 'learning_rate': 0.0003933333333333333, 'epoch': 0.84}
{'loss': 2.0111, 'grad_norm': 0.44265103340148926, 'learning_rate': 0.00038666666666666667, 'epoch': 0.88}
{'loss': 2.3696, 'grad_norm': 0.38920921087265015, 'learning_rate': 0.00038, 'epoch': 0.92}
{'loss': 2.2807, 'grad_norm': 0.4949444830417633, 'learning_rate': 0.0003733333333333334, 'epoch': 0.96}
{'loss': 2.1141, 'grad_norm': 0.47524306178092957, 'learning_rate': 0.00036666666666666667, 'epoch': 1.0}
{'loss': 2.0956, 'grad_norm': 0.4295581579208374, 'learning_rate': 0.00035999999999999997, 'epoch': 1.04}
{'loss': 1.8039, 'grad_norm': 0.48058292269706726, 'learning_rate': 0.0003533333333333333, 'epoch': 1.08}
{'loss': 1.8919, 'grad_norm': 0.43335437774658203, 'learning_rate': 0.00034666666666666667, 'epoch': 1.12}
{'loss': 2.0014, 'grad_norm': 0.43389829993247986, 'learning_rate': 0.00034, 'epoch': 1.16}
{'loss': 2.0514, 'grad_norm': 0.3574204444885254, 'learning_rate': 0.0003333333333333333, 'epoch': 1.2}
{'loss': 1.7721, 'grad_norm': 0.48469507694244385, 'learning_rate': 0.0003266666666666667, 'epoch': 1.24}
{'loss': 2.192, 'grad_norm': 0.45652443170547485, 'learning_rate': 0.00032, 'epoch': 1.28}
{'loss': 1.9202, 'grad_norm': 0.4326837658882141, 'learning_rate': 0.0003133333333333334, 'epoch': 1.32}
{'loss': 2.1188, 'grad_norm': 0.5550878643989563, 'learning_rate': 0.0003066666666666667, 'epoch': 1.36}
{'loss': 1.8295, 'grad_norm': 0.5016399025917053, 'learning_rate': 0.0003, 'epoch': 1.4}
{'loss': 1.8705, 'grad_norm': 0.49745291471481323, 'learning_rate': 0.0002933333333333333, 'epoch': 1.44}
{'loss': 1.8342, 'grad_norm': 0.492167592048645, 'learning_rate': 0.0002866666666666667, 'epoch': 1.48}
{'loss': 1.7577, 'grad_norm': 0.5224279165267944, 'learning_rate': 0.00028000000000000003, 'epoch': 1.52}
{'loss': 1.8713, 'grad_norm': 0.49760133028030396, 'learning_rate': 0.00027333333333333333, 'epoch': 1.56}
{'loss': 2.0461, 'grad_norm': 0.5617117881774902, 'learning_rate': 0.0002666666666666667, 'epoch': 1.6}
{'loss': 1.7304, 'grad_norm': 0.5543932914733887, 'learning_rate': 0.00026000000000000003, 'epoch': 1.64}
{'loss': 1.9795, 'grad_norm': 0.5795474648475647, 'learning_rate': 0.0002533333333333334, 'epoch': 1.68}
{'loss': 1.6829, 'grad_norm': 0.5506756901741028, 'learning_rate': 0.0002466666666666667, 'epoch': 1.72}
{'loss': 1.8427, 'grad_norm': 0.4874078631401062, 'learning_rate': 0.00024, 'epoch': 1.76}
{'loss': 1.6471, 'grad_norm': 0.5686566233634949, 'learning_rate': 0.00023333333333333333, 'epoch': 1.8}
{'loss': 1.8682, 'grad_norm': 0.6462027430534363, 'learning_rate': 0.00022666666666666666, 'epoch': 1.84}
{'loss': 1.8181, 'grad_norm': 0.5210750699043274, 'learning_rate': 0.00022, 'epoch': 1.88}
{'loss': 1.7958, 'grad_norm': 0.5557394027709961, 'learning_rate': 0.00021333333333333336, 'epoch': 1.92}
{'loss': 1.8179, 'grad_norm': 0.6302048563957214, 'learning_rate': 0.00020666666666666666, 'epoch': 1.96}
{'loss': 1.9095, 'grad_norm': 0.7394988536834717, 'learning_rate': 0.0002, 'epoch': 2.0}
{'loss': 1.8178, 'grad_norm': 0.6099331974983215, 'learning_rate': 0.00019333333333333333, 'epoch': 2.04}
{'loss': 1.5337, 'grad_norm': 0.6167904138565063, 'learning_rate': 0.0001866666666666667, 'epoch': 2.08}
{'loss': 1.4716, 'grad_norm': 0.7103798389434814, 'learning_rate': 0.00017999999999999998, 'epoch': 2.12}
{'loss': 1.4774, 'grad_norm': 0.5622888803482056, 'learning_rate': 0.00017333333333333334, 'epoch': 2.16}
{'loss': 1.3795, 'grad_norm': 0.7661318182945251, 'learning_rate': 0.00016666666666666666, 'epoch': 2.2}
{'loss': 1.3991, 'grad_norm': 0.9255890846252441, 'learning_rate': 0.00016, 'epoch': 2.24}
{'loss': 1.4993, 'grad_norm': 0.6554385423660278, 'learning_rate': 0.00015333333333333334, 'epoch': 2.28}
{'loss': 1.573, 'grad_norm': 0.7492340207099915, 'learning_rate': 0.00014666666666666666, 'epoch': 2.32}
{'loss': 1.6713, 'grad_norm': 0.716728925704956, 'learning_rate': 0.00014000000000000001, 'epoch': 2.36}
{'loss': 1.4714, 'grad_norm': 0.7100610136985779, 'learning_rate': 0.00013333333333333334, 'epoch': 2.4}
{'loss': 1.37, 'grad_norm': 0.7225086688995361, 'learning_rate': 0.0001266666666666667, 'epoch': 2.44}
{'loss': 1.5104, 'grad_norm': 0.8038702011108398, 'learning_rate': 0.00012, 'epoch': 2.48}
{'loss': 1.4556, 'grad_norm': 0.6626554727554321, 'learning_rate': 0.00011333333333333333, 'epoch': 2.52}
{'loss': 1.468, 'grad_norm': 0.721865713596344, 'learning_rate': 0.00010666666666666668, 'epoch': 2.56}
{'loss': 1.5187, 'grad_norm': 0.7580734491348267, 'learning_rate': 0.0001, 'epoch': 2.6}
{'loss': 1.4056, 'grad_norm': 0.8482427597045898, 'learning_rate': 9.333333333333334e-05, 'epoch': 2.64}
{'loss': 1.7013, 'grad_norm': 0.8440435528755188, 'learning_rate': 8.666666666666667e-05, 'epoch': 2.68}
{'loss': 1.7156, 'grad_norm': 0.7405182719230652, 'learning_rate': 8e-05, 'epoch': 2.72}
{'loss': 1.3851, 'grad_norm': 0.8504939079284668, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.76}
{'loss': 1.579, 'grad_norm': 0.8333661556243896, 'learning_rate': 6.666666666666667e-05, 'epoch': 2.8}
{'loss': 1.3138, 'grad_norm': 0.9110100865364075, 'learning_rate': 6e-05, 'epoch': 2.84}
{'loss': 1.4051, 'grad_norm': 0.8336772918701172, 'learning_rate': 5.333333333333334e-05, 'epoch': 2.88}
{'loss': 1.5795, 'grad_norm': 0.8652246594429016, 'learning_rate': 4.666666666666667e-05, 'epoch': 2.92}
{'loss': 1.493, 'grad_norm': 0.7538944482803345, 'learning_rate': 4e-05, 'epoch': 2.96}
{'loss': 1.6307, 'grad_norm': 0.7413374185562134, 'learning_rate': 3.3333333333333335e-05, 'epoch': 3.0}
{'loss': 1.3908, 'grad_norm': 0.8755780458450317, 'learning_rate': 2.666666666666667e-05, 'epoch': 3.04}
{'loss': 1.3043, 'grad_norm': 0.8024923205375671, 'learning_rate': 2e-05, 'epoch': 3.08}
{'loss': 1.325, 'grad_norm': 0.7924370169639587, 'learning_rate': 1.3333333333333335e-05, 'epoch': 3.12}
{'loss': 1.0941, 'grad_norm': 0.9583236575126648, 'learning_rate': 6.6666666666666675e-06, 'epoch': 3.16}
{'loss': 1.1557, 'grad_norm': 0.8483467102050781, 'learning_rate': 0.0, 'epoch': 3.2}
{'train_runtime': 1071.7335, 'train_samples_per_second': 0.597, 'train_steps_per_second': 0.075, 'train_loss': 1.86238531768322, 'epoch': 3.2}
Training completed.
Traceback (most recent call last):
  File "/home/mateo/bastos-finetune/finetune.py", line 130, in <module>
    "final_loss": trainer_stats.loss,
AttributeError: 'TrainOutput' object has no attribute 'loss'
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 1.407 MB of 1.420 MB uploadedwandb: / 1.976 MB of 4.041 MB uploadedwandb: - 3.446 MB of 4.041 MB uploadedwandb: \ 4.041 MB of 4.041 MB uploadedwandb: | 4.041 MB of 4.041 MB uploadedwandb: / 4.041 MB of 4.041 MB uploadedwandb: - 4.041 MB of 4.041 MB uploadedwandb: \ 4.041 MB of 4.041 MB uploadedwandb: | 4.041 MB of 4.041 MB uploadedwandb: / 4.041 MB of 4.041 MB uploadedwandb: - 4.041 MB of 4.041 MB uploadedwandb: \ 4.041 MB of 4.041 MB uploadedwandb: 
wandb: Run history:
wandb:        dataset_size â–
wandb:         train/epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:   train/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:     train/grad_norm â–‚â–…â–ƒâ–„â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–†â–…â–…â–…â–…â–†â–‡â–‡â–ˆâ–‡â–†â–‡â–‡
wandb: train/learning_rate â–‚â–…â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:          train/loss â–ˆâ–ˆâ–†â–†â–†â–…â–†â–„â–…â–…â–…â–†â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–
wandb: 
wandb: Run summary:
wandb:             dataset_size 200
wandb:               total_flos 1.9205027453730816e+16
wandb:              train/epoch 3.2
wandb:        train/global_step 80
wandb:          train/grad_norm 0.84835
wandb:      train/learning_rate 0.0
wandb:               train/loss 1.1557
wandb:               train_loss 1.86239
wandb:            train_runtime 1071.7335
wandb: train_samples_per_second 0.597
wandb:   train_steps_per_second 0.075
wandb: 
wandb: ğŸš€ View run smart-aardvark-1 at: https://wandb.ai/finentune/bastos/runs/ge8tkz0r
wandb: â­ï¸ View project at: https://wandb.ai/finentune/bastos
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240726_102437-ge8tkz0r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
