nohup: ignoring input
Unsloth unsuccessfully patched LoraLayer.update_layer. Please file a bug report.
Luckily, your training run will still work in the meantime!
wandb: Currently logged in as: m19182 (finentune). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /home/mateo/bastos-finetune/wandb/run-20240726_102437-ge8tkz0r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-aardvark-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/finentune/bastos
wandb: üöÄ View run at https://wandb.ai/finentune/bastos/runs/ge8tkz0r
Not an error, but Unsloth cannot patch MLP layers with our manual autograd engine since either LoRA adapters
are not enabled or a bias term (like in Qwen) is used.
Not an error, but Unsloth cannot patch Attention layers with our manual autograd engine since either LoRA adapters
are not enabled or a bias term (like in Qwen) is used.
Not an error, but Unsloth cannot patch O projection layer with our manual autograd engine since either LoRA adapters
are not enabled or a bias term (like in Qwen) is used.
Unsloth 2024.7 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.
ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.
Dataset size: 200
==((====))==  Unsloth: Fast Llama patching release 2024.7
   \\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.69 GB. Platform = Linux.
O^O/ \_/ \    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Map (num_proc=2):   0%|          | 0/200 [00:00<?, ? examples/s]Map (num_proc=2):  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [00:00<00:00, 256.79 examples/s]Map (num_proc=2): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 374.57 examples/s]
max_steps is given, it will override any value given in num_train_epochs
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1
   \\   /|    Num examples = 200 | Num Epochs = 4
O^O/ \_/ \    Batch size per device = 2 | Gradient Accumulation steps = 4
\        /    Total batch size = 8 | Total steps = 80
 "-____-"     Number of trainable parameters = 41,943,040
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
Starting training...
  0%|          | 0/80 [00:00<?, ?it/s]  1%|‚ñè         | 1/80 [00:07<10:27,  7.95s/it]                                                1%|‚ñè         | 1/80 [00:07<10:27,  7.95s/it]  2%|‚ñé         | 2/80 [00:13<08:15,  6.35s/it]                                                2%|‚ñé         | 2/80 [00:13<08:15,  6.35s/it]  4%|‚ñç         | 3/80 [00:40<20:15, 15.78s/it]                                                4%|‚ñç         | 3/80 [00:40<20:15, 15.78s/it]  5%|‚ñå         | 4/80 [00:44<14:30, 11.45s/it]                                                5%|‚ñå         | 4/80 [00:44<14:30, 11.45s/it]  6%|‚ñã         | 5/80 [01:11<21:15, 17.01s/it]                                                6%|‚ñã         | 5/80 [01:11<21:15, 17.01s/it]  8%|‚ñä         | 6/80 [01:17<16:13, 13.15s/it]                                                8%|‚ñä         | 6/80 [01:17<16:13, 13.15s/it]  9%|‚ñâ         | 7/80 [01:22<12:37, 10.38s/it]                                                9%|‚ñâ         | 7/80 [01:22<12:37, 10.38s/it] 10%|‚ñà         | 8/80 [01:46<17:55, 14.94s/it]                                               10%|‚ñà         | 8/80 [01:46<17:55, 14.94s/it] 11%|‚ñà‚ñè        | 9/80 [01:50<13:38, 11.52s/it]                                               11%|‚ñà‚ñè        | 9/80 [01:50<13:38, 11.52s/it] 12%|‚ñà‚ñé        | 10/80 [02:14<17:56, 15.38s/it]                                                12%|‚ñà‚ñé        | 10/80 [02:14<17:56, 15.38s/it] 14%|‚ñà‚ñç        | 11/80 [02:19<13:45, 11.96s/it]                                                14%|‚ñà‚ñç        | 11/80 [02:19<13:45, 11.96s/it] 15%|‚ñà‚ñå        | 12/80 [02:26<12:02, 10.63s/it]                                                15%|‚ñà‚ñå        | 12/80 [02:26<12:02, 10.63s/it] 16%|‚ñà‚ñã        | 13/80 [02:52<17:09, 15.36s/it]                                                16%|‚ñà‚ñã        | 13/80 [02:52<17:09, 15.36s/it] 18%|‚ñà‚ñä        | 14/80 [03:00<14:27, 13.14s/it]                                                18%|‚ñà‚ñä        | 14/80 [03:00<14:27, 13.14s/it] 19%|‚ñà‚ñâ        | 15/80 [03:25<17:51, 16.48s/it]                                                19%|‚ñà‚ñâ        | 15/80 [03:25<17:51, 16.48s/it] 20%|‚ñà‚ñà        | 16/80 [03:30<13:58, 13.11s/it]                                                20%|‚ñà‚ñà        | 16/80 [03:30<13:58, 13.11s/it] 21%|‚ñà‚ñà‚ñè       | 17/80 [03:35<11:18, 10.77s/it]                                                21%|‚ñà‚ñà‚ñè       | 17/80 [03:35<11:18, 10.77s/it] 22%|‚ñà‚ñà‚ñé       | 18/80 [04:00<15:22, 14.88s/it]                                                22%|‚ñà‚ñà‚ñé       | 18/80 [04:00<15:22, 14.88s/it] 24%|‚ñà‚ñà‚ñç       | 19/80 [04:03<11:43, 11.53s/it]                                                24%|‚ñà‚ñà‚ñç       | 19/80 [04:03<11:43, 11.53s/it] 25%|‚ñà‚ñà‚ñå       | 20/80 [04:27<15:01, 15.03s/it]                                                25%|‚ñà‚ñà‚ñå       | 20/80 [04:27<15:01, 15.03s/it] 26%|‚ñà‚ñà‚ñã       | 21/80 [04:31<11:35, 11.79s/it]                                                26%|‚ñà‚ñà‚ñã       | 21/80 [04:31<11:35, 11.79s/it] 28%|‚ñà‚ñà‚ñä       | 22/80 [04:35<09:09,  9.48s/it]                                                28%|‚ñà‚ñà‚ñä       | 22/80 [04:35<09:09,  9.48s/it] 29%|‚ñà‚ñà‚ñâ       | 23/80 [05:04<14:28, 15.23s/it]                                                29%|‚ñà‚ñà‚ñâ       | 23/80 [05:04<14:28, 15.23s/it] 30%|‚ñà‚ñà‚ñà       | 24/80 [05:09<11:26, 12.25s/it]                                                30%|‚ñà‚ñà‚ñà       | 24/80 [05:09<11:26, 12.25s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 25/80 [05:33<14:26, 15.76s/it]                                                31%|‚ñà‚ñà‚ñà‚ñè      | 25/80 [05:33<14:26, 15.76s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 26/80 [05:39<11:41, 12.98s/it]                                                32%|‚ñà‚ñà‚ñà‚ñé      | 26/80 [05:39<11:41, 12.98s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 27/80 [05:44<09:09, 10.37s/it]                                                34%|‚ñà‚ñà‚ñà‚ñç      | 27/80 [05:44<09:09, 10.37s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 28/80 [06:08<12:36, 14.55s/it]                                                35%|‚ñà‚ñà‚ñà‚ñå      | 28/80 [06:08<12:36, 14.55s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 29/80 [06:12<09:46, 11.51s/it]                                                36%|‚ñà‚ñà‚ñà‚ñã      | 29/80 [06:12<09:46, 11.51s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 30/80 [06:41<13:51, 16.62s/it]                                                38%|‚ñà‚ñà‚ñà‚ñä      | 30/80 [06:41<13:51, 16.62s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 31/80 [06:44<10:21, 12.69s/it]                                                39%|‚ñà‚ñà‚ñà‚ñâ      | 31/80 [06:44<10:21, 12.69s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 32/80 [06:52<08:53, 11.11s/it]                                                40%|‚ñà‚ñà‚ñà‚ñà      | 32/80 [06:52<08:53, 11.11s/it] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 33/80 [07:18<12:20, 15.75s/it]                                                41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 33/80 [07:18<12:20, 15.75s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 34/80 [07:25<09:53, 12.90s/it]                                                42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 34/80 [07:25<09:53, 12.90s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 35/80 [07:50<12:23, 16.52s/it]                                                44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 35/80 [07:50<12:23, 16.52s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 36/80 [07:55<09:38, 13.16s/it]                                                45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 36/80 [07:55<09:38, 13.16s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 37/80 [08:00<07:44, 10.80s/it]                                                46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 37/80 [08:00<07:44, 10.80s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 38/80 [08:24<10:20, 14.78s/it]                                                48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 38/80 [08:24<10:20, 14.78s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 39/80 [08:32<08:34, 12.54s/it]                                                49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 39/80 [08:32<08:34, 12.54s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 40/80 [08:59<11:14, 16.86s/it]                                                50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 40/80 [08:59<11:14, 16.86s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 41/80 [09:03<08:32, 13.13s/it]                                                51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 41/80 [09:03<08:32, 13.13s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 42/80 [09:08<06:46, 10.69s/it]                                                52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 42/80 [09:08<06:46, 10.69s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 43/80 [09:32<09:05, 14.75s/it]                                                54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 43/80 [09:32<09:05, 14.75s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 44/80 [09:40<07:36, 12.69s/it]                                                55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 44/80 [09:40<07:36, 12.69s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 45/80 [10:04<09:19, 15.99s/it]                                                56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 45/80 [10:04<09:19, 15.99s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 46/80 [10:08<07:07, 12.57s/it]                                                57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 46/80 [10:08<07:07, 12.57s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 47/80 [10:14<05:43, 10.40s/it]                                                59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 47/80 [10:14<05:43, 10.40s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 48/80 [10:39<08:00, 15.01s/it]                                                60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 48/80 [10:39<08:00, 15.01s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 49/80 [10:44<06:04, 11.75s/it]                                                61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 49/80 [10:44<06:04, 11.75s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 50/80 [11:08<07:45, 15.51s/it]                                                62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 50/80 [11:08<07:45, 15.51s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 51/80 [11:13<06:02, 12.49s/it]                                                64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 51/80 [11:13<06:02, 12.49s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 52/80 [11:19<04:48, 10.32s/it]                                                65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 52/80 [11:19<04:48, 10.32s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 53/80 [11:43<06:29, 14.43s/it]                                                66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 53/80 [11:43<06:29, 14.43s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 54/80 [11:49<05:13, 12.04s/it]                                                68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 54/80 [11:49<05:13, 12.04s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 55/80 [12:14<06:41, 16.04s/it]                                                69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 55/80 [12:14<06:41, 16.04s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 56/80 [12:18<04:57, 12.39s/it]                                                70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 56/80 [12:18<04:57, 12.39s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 57/80 [12:24<03:59, 10.40s/it]                                                71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 57/80 [12:24<03:59, 10.40s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/80 [12:51<05:34, 15.22s/it]                                                72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/80 [12:51<05:34, 15.22s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 59/80 [12:58<04:27, 12.75s/it]                                                74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 59/80 [12:58<04:27, 12.75s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 60/80 [13:24<05:35, 16.77s/it]                                                75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 60/80 [13:24<05:35, 16.77s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 61/80 [13:28<04:08, 13.06s/it]                                                76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 61/80 [13:28<04:08, 13.06s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 62/80 [13:33<03:10, 10.60s/it]                                                78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 62/80 [13:33<03:10, 10.60s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/80 [13:58<04:15, 15.01s/it]                                                79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/80 [13:58<04:15, 15.01s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/80 [14:05<03:21, 12.57s/it]                                                80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/80 [14:05<03:21, 12.57s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 65/80 [14:32<04:13, 16.90s/it]                                                81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 65/80 [14:32<04:13, 16.90s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 66/80 [14:36<03:01, 12.97s/it]                                                82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 66/80 [14:36<03:01, 12.97s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 67/80 [14:41<02:18, 10.65s/it]                                                84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 67/80 [14:41<02:18, 10.65s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 68/80 [15:10<03:11, 16.00s/it]                                                85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 68/80 [15:10<03:11, 16.00s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 69/80 [15:15<02:19, 12.65s/it]                                                86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 69/80 [15:15<02:19, 12.65s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 70/80 [15:39<02:42, 16.29s/it]                                                88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 70/80 [15:39<02:42, 16.29s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 71/80 [15:44<01:55, 12.83s/it]                                                89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 71/80 [15:44<01:55, 12.83s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 72/80 [15:49<01:22, 10.36s/it]                                                90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 72/80 [15:49<01:22, 10.36s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 73/80 [16:13<01:42, 14.62s/it]                                                91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 73/80 [16:13<01:42, 14.62s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 74/80 [16:18<01:10, 11.81s/it]                                                92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 74/80 [16:18<01:10, 11.81s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 75/80 [16:45<01:20, 16.20s/it]                                                94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 75/80 [16:45<01:20, 16.20s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 76/80 [16:50<00:51, 12.82s/it]                                                95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 76/80 [16:50<00:51, 12.82s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 77/80 [16:56<00:32, 10.68s/it]                                                96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 77/80 [16:56<00:32, 10.68s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 78/80 [17:20<00:29, 14.84s/it]                                                98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 78/80 [17:20<00:29, 14.84s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 79/80 [17:24<00:11, 11.59s/it]                                                99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 79/80 [17:24<00:11, 11.59s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [17:49<00:00, 15.58s/it]                                               100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [17:49<00:00, 15.58s/it]                                               100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [17:51<00:00, 15.58s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [17:51<00:00, 13.39s/it]
{'loss': 2.8671, 'grad_norm': 0.45255616307258606, 'learning_rate': 0.0001, 'epoch': 0.04}
{'loss': 2.7843, 'grad_norm': 0.5766644477844238, 'learning_rate': 0.0002, 'epoch': 0.08}
{'loss': 2.8813, 'grad_norm': 0.6646426320075989, 'learning_rate': 0.0003, 'epoch': 0.12}
{'loss': 2.7391, 'grad_norm': 0.6037139892578125, 'learning_rate': 0.0004, 'epoch': 0.16}
{'loss': 2.5031, 'grad_norm': 0.526724100112915, 'learning_rate': 0.0005, 'epoch': 0.2}
{'loss': 2.6722, 'grad_norm': 0.47797271609306335, 'learning_rate': 0.0004933333333333334, 'epoch': 0.24}
{'loss': 2.2733, 'grad_norm': 0.5986953973770142, 'learning_rate': 0.0004866666666666667, 'epoch': 0.28}
{'loss': 2.321, 'grad_norm': 0.42159485816955566, 'learning_rate': 0.00048, 'epoch': 0.32}
{'loss': 2.3311, 'grad_norm': 0.43944916129112244, 'learning_rate': 0.00047333333333333336, 'epoch': 0.36}
{'loss': 2.0285, 'grad_norm': 0.4654865562915802, 'learning_rate': 0.00046666666666666666, 'epoch': 0.4}
{'loss': 2.0646, 'grad_norm': 0.39786839485168457, 'learning_rate': 0.00046, 'epoch': 0.44}
{'loss': 2.11, 'grad_norm': 0.3247736394405365, 'learning_rate': 0.0004533333333333333, 'epoch': 0.48}
{'loss': 2.4682, 'grad_norm': 0.45549461245536804, 'learning_rate': 0.00044666666666666666, 'epoch': 0.52}
{'loss': 2.3632, 'grad_norm': 0.3898145258426666, 'learning_rate': 0.00044, 'epoch': 0.56}
{'loss': 2.0004, 'grad_norm': 0.46137863397598267, 'learning_rate': 0.00043333333333333337, 'epoch': 0.6}
{'loss': 2.0986, 'grad_norm': 0.39024701714515686, 'learning_rate': 0.0004266666666666667, 'epoch': 0.64}
{'loss': 2.0759, 'grad_norm': 0.4270508885383606, 'learning_rate': 0.00042, 'epoch': 0.68}
{'loss': 2.1876, 'grad_norm': 0.4054321050643921, 'learning_rate': 0.0004133333333333333, 'epoch': 0.72}
{'loss': 2.1672, 'grad_norm': 0.45364221930503845, 'learning_rate': 0.00040666666666666667, 'epoch': 0.76}
{'loss': 1.8181, 'grad_norm': 0.44175463914871216, 'learning_rate': 0.0004, 'epoch': 0.8}
{'loss': 2.2162, 'grad_norm': 0.5176711082458496, 'learning_rate': 0.0003933333333333333, 'epoch': 0.84}
{'loss': 2.0111, 'grad_norm': 0.44265103340148926, 'learning_rate': 0.00038666666666666667, 'epoch': 0.88}
{'loss': 2.3696, 'grad_norm': 0.38920921087265015, 'learning_rate': 0.00038, 'epoch': 0.92}
{'loss': 2.2807, 'grad_norm': 0.4949444830417633, 'learning_rate': 0.0003733333333333334, 'epoch': 0.96}
{'loss': 2.1141, 'grad_norm': 0.47524306178092957, 'learning_rate': 0.00036666666666666667, 'epoch': 1.0}
{'loss': 2.0956, 'grad_norm': 0.4295581579208374, 'learning_rate': 0.00035999999999999997, 'epoch': 1.04}
{'loss': 1.8039, 'grad_norm': 0.48058292269706726, 'learning_rate': 0.0003533333333333333, 'epoch': 1.08}
{'loss': 1.8919, 'grad_norm': 0.43335437774658203, 'learning_rate': 0.00034666666666666667, 'epoch': 1.12}
{'loss': 2.0014, 'grad_norm': 0.43389829993247986, 'learning_rate': 0.00034, 'epoch': 1.16}
{'loss': 2.0514, 'grad_norm': 0.3574204444885254, 'learning_rate': 0.0003333333333333333, 'epoch': 1.2}
{'loss': 1.7721, 'grad_norm': 0.48469507694244385, 'learning_rate': 0.0003266666666666667, 'epoch': 1.24}
{'loss': 2.192, 'grad_norm': 0.45652443170547485, 'learning_rate': 0.00032, 'epoch': 1.28}
{'loss': 1.9202, 'grad_norm': 0.4326837658882141, 'learning_rate': 0.0003133333333333334, 'epoch': 1.32}
{'loss': 2.1188, 'grad_norm': 0.5550878643989563, 'learning_rate': 0.0003066666666666667, 'epoch': 1.36}
{'loss': 1.8295, 'grad_norm': 0.5016399025917053, 'learning_rate': 0.0003, 'epoch': 1.4}
{'loss': 1.8705, 'grad_norm': 0.49745291471481323, 'learning_rate': 0.0002933333333333333, 'epoch': 1.44}
{'loss': 1.8342, 'grad_norm': 0.492167592048645, 'learning_rate': 0.0002866666666666667, 'epoch': 1.48}
{'loss': 1.7577, 'grad_norm': 0.5224279165267944, 'learning_rate': 0.00028000000000000003, 'epoch': 1.52}
{'loss': 1.8713, 'grad_norm': 0.49760133028030396, 'learning_rate': 0.00027333333333333333, 'epoch': 1.56}
{'loss': 2.0461, 'grad_norm': 0.5617117881774902, 'learning_rate': 0.0002666666666666667, 'epoch': 1.6}
{'loss': 1.7304, 'grad_norm': 0.5543932914733887, 'learning_rate': 0.00026000000000000003, 'epoch': 1.64}
{'loss': 1.9795, 'grad_norm': 0.5795474648475647, 'learning_rate': 0.0002533333333333334, 'epoch': 1.68}
{'loss': 1.6829, 'grad_norm': 0.5506756901741028, 'learning_rate': 0.0002466666666666667, 'epoch': 1.72}
{'loss': 1.8427, 'grad_norm': 0.4874078631401062, 'learning_rate': 0.00024, 'epoch': 1.76}
{'loss': 1.6471, 'grad_norm': 0.5686566233634949, 'learning_rate': 0.00023333333333333333, 'epoch': 1.8}
{'loss': 1.8682, 'grad_norm': 0.6462027430534363, 'learning_rate': 0.00022666666666666666, 'epoch': 1.84}
{'loss': 1.8181, 'grad_norm': 0.5210750699043274, 'learning_rate': 0.00022, 'epoch': 1.88}
{'loss': 1.7958, 'grad_norm': 0.5557394027709961, 'learning_rate': 0.00021333333333333336, 'epoch': 1.92}
{'loss': 1.8179, 'grad_norm': 0.6302048563957214, 'learning_rate': 0.00020666666666666666, 'epoch': 1.96}
{'loss': 1.9095, 'grad_norm': 0.7394988536834717, 'learning_rate': 0.0002, 'epoch': 2.0}
{'loss': 1.8178, 'grad_norm': 0.6099331974983215, 'learning_rate': 0.00019333333333333333, 'epoch': 2.04}
{'loss': 1.5337, 'grad_norm': 0.6167904138565063, 'learning_rate': 0.0001866666666666667, 'epoch': 2.08}
{'loss': 1.4716, 'grad_norm': 0.7103798389434814, 'learning_rate': 0.00017999999999999998, 'epoch': 2.12}
{'loss': 1.4774, 'grad_norm': 0.5622888803482056, 'learning_rate': 0.00017333333333333334, 'epoch': 2.16}
{'loss': 1.3795, 'grad_norm': 0.7661318182945251, 'learning_rate': 0.00016666666666666666, 'epoch': 2.2}
{'loss': 1.3991, 'grad_norm': 0.9255890846252441, 'learning_rate': 0.00016, 'epoch': 2.24}
{'loss': 1.4993, 'grad_norm': 0.6554385423660278, 'learning_rate': 0.00015333333333333334, 'epoch': 2.28}
{'loss': 1.573, 'grad_norm': 0.7492340207099915, 'learning_rate': 0.00014666666666666666, 'epoch': 2.32}
{'loss': 1.6713, 'grad_norm': 0.716728925704956, 'learning_rate': 0.00014000000000000001, 'epoch': 2.36}
{'loss': 1.4714, 'grad_norm': 0.7100610136985779, 'learning_rate': 0.00013333333333333334, 'epoch': 2.4}
{'loss': 1.37, 'grad_norm': 0.7225086688995361, 'learning_rate': 0.0001266666666666667, 'epoch': 2.44}
{'loss': 1.5104, 'grad_norm': 0.8038702011108398, 'learning_rate': 0.00012, 'epoch': 2.48}
{'loss': 1.4556, 'grad_norm': 0.6626554727554321, 'learning_rate': 0.00011333333333333333, 'epoch': 2.52}
{'loss': 1.468, 'grad_norm': 0.721865713596344, 'learning_rate': 0.00010666666666666668, 'epoch': 2.56}
{'loss': 1.5187, 'grad_norm': 0.7580734491348267, 'learning_rate': 0.0001, 'epoch': 2.6}
{'loss': 1.4056, 'grad_norm': 0.8482427597045898, 'learning_rate': 9.333333333333334e-05, 'epoch': 2.64}
{'loss': 1.7013, 'grad_norm': 0.8440435528755188, 'learning_rate': 8.666666666666667e-05, 'epoch': 2.68}
{'loss': 1.7156, 'grad_norm': 0.7405182719230652, 'learning_rate': 8e-05, 'epoch': 2.72}
{'loss': 1.3851, 'grad_norm': 0.8504939079284668, 'learning_rate': 7.333333333333333e-05, 'epoch': 2.76}
{'loss': 1.579, 'grad_norm': 0.8333661556243896, 'learning_rate': 6.666666666666667e-05, 'epoch': 2.8}
{'loss': 1.3138, 'grad_norm': 0.9110100865364075, 'learning_rate': 6e-05, 'epoch': 2.84}
{'loss': 1.4051, 'grad_norm': 0.8336772918701172, 'learning_rate': 5.333333333333334e-05, 'epoch': 2.88}
{'loss': 1.5795, 'grad_norm': 0.8652246594429016, 'learning_rate': 4.666666666666667e-05, 'epoch': 2.92}
{'loss': 1.493, 'grad_norm': 0.7538944482803345, 'learning_rate': 4e-05, 'epoch': 2.96}
{'loss': 1.6307, 'grad_norm': 0.7413374185562134, 'learning_rate': 3.3333333333333335e-05, 'epoch': 3.0}
{'loss': 1.3908, 'grad_norm': 0.8755780458450317, 'learning_rate': 2.666666666666667e-05, 'epoch': 3.04}
{'loss': 1.3043, 'grad_norm': 0.8024923205375671, 'learning_rate': 2e-05, 'epoch': 3.08}
{'loss': 1.325, 'grad_norm': 0.7924370169639587, 'learning_rate': 1.3333333333333335e-05, 'epoch': 3.12}
{'loss': 1.0941, 'grad_norm': 0.9583236575126648, 'learning_rate': 6.6666666666666675e-06, 'epoch': 3.16}
{'loss': 1.1557, 'grad_norm': 0.8483467102050781, 'learning_rate': 0.0, 'epoch': 3.2}
{'train_runtime': 1071.7335, 'train_samples_per_second': 0.597, 'train_steps_per_second': 0.075, 'train_loss': 1.86238531768322, 'epoch': 3.2}
Training completed.
Traceback (most recent call last):
  File "/home/mateo/bastos-finetune/finetune.py", line 130, in <module>
    "final_loss": trainer_stats.loss,
AttributeError: 'TrainOutput' object has no attribute 'loss'
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 1.407 MB of 1.420 MB uploadedwandb: / 1.976 MB of 4.041 MB uploadedwandb: - 3.446 MB of 4.041 MB uploadedwandb: \ 4.041 MB of 4.041 MB uploadedwandb: | 4.041 MB of 4.041 MB uploadedwandb: / 4.041 MB of 4.041 MB uploadedwandb: - 4.041 MB of 4.041 MB uploadedwandb: \ 4.041 MB of 4.041 MB uploadedwandb: | 4.041 MB of 4.041 MB uploadedwandb: / 4.041 MB of 4.041 MB uploadedwandb: - 4.041 MB of 4.041 MB uploadedwandb: \ 4.041 MB of 4.041 MB uploadedwandb: 
wandb: Run history:
wandb:        dataset_size ‚ñÅ
wandb:         train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:     train/grad_norm ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá
wandb: train/learning_rate ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/loss ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:             dataset_size 200
wandb:               total_flos 1.9205027453730816e+16
wandb:              train/epoch 3.2
wandb:        train/global_step 80
wandb:          train/grad_norm 0.84835
wandb:      train/learning_rate 0.0
wandb:               train/loss 1.1557
wandb:               train_loss 1.86239
wandb:            train_runtime 1071.7335
wandb: train_samples_per_second 0.597
wandb:   train_steps_per_second 0.075
wandb: 
wandb: üöÄ View run smart-aardvark-1 at: https://wandb.ai/finentune/bastos/runs/ge8tkz0r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/finentune/bastos
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240726_102437-ge8tkz0r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
